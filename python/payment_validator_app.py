# -*- coding: utf-8 -*-
"""easyocr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ALPqyCF19rpXPxfec2twHJYfRk_h5MRP

# Proyecto para identificar datos en capturas de transferencias

## Instalacion de dependencias
"""



"""## Cargar el modelo OCR para identificar datos de imagenes"""

import easyocr
from PIL import Image
import spacy
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
import glob
import re
import unicodedata
from datetime import datetime
import pandas as pd
import re
from datetime import datetime

reader = easyocr.Reader(['es'], gpu=True)

def read_and_parse_images(folder_path):
    startTime = datetime.now()

    print("Hora inicio:", startTime)

    # 1. Crear lector de EasyOCR (espa√±ol )

    """## Leer todas las imagenes de un folder y analizar el contenido para extraer texto"""

    # 2. Leer texto desdlas carpetas de imagenes
    resultados = {}

    #folder_path = "drive/MyDrive/TalentoTechIA/transferencias/test/"
    # folder_path = "./images/test/"
    imagenes = glob.glob(folder_path + "*.*")

    # analizar datos bancolombia
    for img_path in imagenes:
        try:
            texto = reader.readtext(img_path, detail=0)  # detail=0 devuelve solo el texto
            resultados[img_path] = "bancolombia," + ( ",".join(texto))
        except Exception as e:
            print(f"Error processing image {img_path}: {e}")
    
    
    endTime = datetime.now()
    print("Hora Fin:", endTime)

    print(f"Total number of results: {len(resultados)}")

    return resultados


#folder_path = "drive/MyDrive/TalentoTechIA/transferencias/test/"
# folder_path = "./images/nequi/"
# imagenes = glob.glob(folder_path + "*.*")

# for img_path in imagenes:
#     try:
#         texto = reader.readtext(img_path, detail=0)  # detail=0 devuelve solo el texto
#         resultados[img_path] = "nequi," + ( ",".join(texto))
#     except Exception as e:
#         print(f"Error processing image {img_path}: {e}")



"""##Funcion para procesar texto."""



# --- Utilidades ---
def limpiar_texto(texto: str) -> str:
    """
    Limpia el texto OCR:
    - Min√∫sculas
    - Normaliza acentos
    - Solo deja letras, n√∫meros, espacios y los s√≠mbolos √∫tiles: - . , : * $
    """
    texto = texto.lower()
    texto = unicodedata.normalize("NFD", texto)
    texto = "".join(c for c in texto if unicodedata.category(c) != "Mn")
    # Permitimos asterisco * y signo $
    texto = re.sub(r"[^a-z0-9\s\-\.,:\*\$]", " ", texto)
    texto = re.sub(r"\s+", " ", texto).strip()
    return texto


def normaliza_guiones(texto: str) -> str:
    return re.sub(r'\s*-\s*', '-', texto)

def normaliza_cuenta(s: str) -> str:
    if not s:
        return s
    s = s.replace('\u00A0', ' ')
    s = re.sub(r'(?<=\d)\s*,\s*(?=\d)', '-', s)
    s = re.sub(r'\s*-\s*', '-', s)
    s = re.sub(r'\s+', '', s)
    s = re.sub(r'-{2,}', '-', s)
    return s

def _is_bank_token(t: str) -> bool:
    return bool(re.search(r'bancolom\w*', t)) or "a la mano" in t

def _is_account_chunk(t: str) -> bool:
    if not re.search(r'[\d*]', t):
        return False
    return not re.search(r'[a-z]', t)

def _clean_segment(seg: str) -> str:
    if '*' in seg:
        return ''.join(ch for ch in seg if ch.isdigit() or ch == '*')
    return re.sub(r'\D', '', seg)

def _join_account_segments(tokens):
    segments = []
    for tok in tokens:
        parts = re.split(r'[-\s]+', tok)
        for p in parts:
            p = p.strip()
            if not p:
                continue
            cleaned = _clean_segment(p)
            if cleaned:
                segments.append(cleaned)
    if len(segments) == 1 and '*' in segments[0]:
        return segments[0]
    return '-'.join(segments)

def _parse_currency_to_int(s: str) -> int:
    s = s.strip().replace(' ', '').replace('.', '').replace(',', '.')
    s = re.sub(r'[^0-9.]', '', s)
    if s.count('.') > 1:
        first = s.find('.')
        s = s[:first+1] + s[first+1:].replace('.', '')
    try:
        return int(round(float(s)))
    except:
        only_digits = re.sub(r'\D', '', s)
        return int(only_digits) if only_digits else 0

def corrige_ceros(cadena: str) -> str:
    """
    Reemplaza todas las ocurrencias recursivas de 'o0' o '0o' por '00'
    hasta que ya no haya coincidencias.
    """
    while True:
        nueva, cambios = re.subn(r'(o0|0o)', '00', cadena)
        if cambios == 0:
            break
        cadena = nueva
    return cadena

def limpia_tokens_ruidosos(tokens: list) -> list:
    basura = {
        "anadir a favoritos", "anadido a favoritos",
        "inicio", "transferir", "consultar", "ayuda", "mi empresa",
        "explorar", "tramites", "ajustes", "solicitudes",
        "perfil", "mis productos", "mover", "facturas",
        "inlclo", "transferlr", "consullar", "anadido", "anadir",
        "favoritos", "a", "producto oriqen", "producto",
        "cuenta de ahorros", "origen"
    }

    filtrados = []
    for t in tokens:
        t_norm = t.strip().lower()
        t = corrige_ceros(t_norm)
        if t_norm in basura:
            break   # üëà cortamos en cuanto aparezca un token basura
        filtrados.append(t)
    return filtrados

# --- Parsers de secciones ---
def parse_producto_destino(texto: str):
    match = re.search(
        r'producto\s*destino[,:\s]+(.+?)(?=(producto\s*origen|valor|valor\s+pagado|costo|categoria|referencia|observaciones|inicio|datos del pago|datos de la transferencia|mis productos|$))',
        texto,
        re.DOTALL
    )
    if not match:
        return None
    fragmento = match.group(1).strip()

    tokens = [normaliza_guiones(t.strip()) for t in re.split(r'[,\n]', fragmento) if t.strip()]

    # print('tokens')
    # print(tokens)


    tokens = limpia_tokens_ruidosos(tokens)
    # print('limpia token ruidosos')
    # print(tokens)


    destino = {"nombre": "", "tipo": "", "cuenta": ""}
    idx_tipo, tipo_detectado = None, None
    for i, tok in enumerate(tokens):
        m = re.search(r'\b(ahorros?|corrientes?)\b', tok)
        if m:
            tipo_detectado = m.group(1)
            idx_tipo = i
            break
    if idx_tipo is None:
        tail = [t for t in tokens if not _is_bank_token(t)]
        collected = []
        for t in reversed(tail):
            if _is_account_chunk(t):
                collected.append(t)
            else:
                break
        if collected:
            cuenta = _join_account_segments(list(reversed(collected)))
            destino["cuenta"] = normaliza_cuenta(cuenta)
        return destino

    destino["tipo"] = "ahorros" if "aho" in tipo_detectado else "corriente"
    destino["nombre"] = " ".join([t for t in tokens[:idx_tipo] if not _is_bank_token(t)])
    tail = [t for t in tokens[idx_tipo+1:] if not _is_bank_token(t)]
    collected = []
    for t in reversed(tail):
        if _is_account_chunk(t):
            collected.append(t)
        else:
            break
    if collected:
        cuenta = _join_account_segments(list(reversed(collected)))
        destino["cuenta"] = normaliza_cuenta(cuenta)
    return destino

def parse_producto_origen(texto: str):
    match = re.search(
        r'producto\s*origen[,:\s]+(.+?)(?=(producto\s*destino|valor|valor\s+pagado|costo|categoria|referencia|observaciones|inicio|datos del pago|datos de la transferencia|$))',
        texto,
        re.DOTALL
    )
    if not match:
        return None
    fragmento = match.group(1).strip()
    tokens = [t.strip() for t in re.split(r'[,\n]', fragmento) if t.strip()]
    origen = {"tipo": "", "cuenta": ""}
    idx_tipo, tipo_detectado = None, None
    for i, tok in enumerate(tokens):
        m = re.search(r'\b(ahorros?|corrientes?)\b', tok)
        if m:
            tipo_detectado = m.group(1)
            idx_tipo = i
            break
    if tipo_detectado:
        origen["tipo"] = "ahorros" if "aho" in tipo_detectado else "corriente"
    tail = tokens[idx_tipo+1:] if idx_tipo is not None else tokens
    tail = [t for t in tail if not _is_bank_token(t)]
    for t in tail:
        if '*' in t and re.search(r'\d', t):
            origen["cuenta"] = _clean_segment(t)
            return origen
    collected = []
    for t in reversed(tail):
        if _is_account_chunk(t):
            collected.append(t)
        else:
            break
    if collected:
        origen["cuenta"] = _join_account_segments(list(reversed(collected)))
    return origen

# texto = "bancolombia,itransferencia exitosa ,comprobante no. 7e9091605401,17 ago 2025,09.16a.m,datos de la transferencia,descripcion del qr,vaca cumple,valor de la transferencia, 150.000,producto destino,cristian camilo nava,ahorros,bancolombia,912 -,216853,48,producto,cuenta de ahorros,ahorros,4271,origen"

# print(parse_transferencia(texto))

"""## funciones para normalizar fechas"""


# --- Meses ---
MESES_MAP = {
    # Espa√±ol
    "ene": "01", "feb": "02", "mar": "03", "abr": "04",
    "may": "05", "jun": "06", "jul": "07", "ago": "08",
    "sep": "09", "sept": "09", "oct": "10", "nov": "11",
    "dic": "12", "dlc": "12",   # OCR: 'dlc' por 'dic'
    # Ingl√©s
    "jan": "01", "feb": "02", "mar": "03", "apr": "04",
    "may": "05", "jun": "06", "jul": "07", "aug": "08",
    "sep": "09", "oct": "10", "nov": "11", "dec": "12",
}

# --- Normalizadores b√°sicos ---
def preprocesa_fecha(texto: str) -> str:
    """Corrige errores OCR comunes en fechas y horas."""
    # Normalizar separadores de hora: 03.45 / 03*45 / 03-45 -> 03:45
    texto = re.sub(r'(\d)\s*[\.,\-\*]+\s*(\d)', r'\1:\2', texto)

    # Normalizar AM/PM con puntos, comas o espacios raros
    texto = re.sub(r'a\W*m', 'am', texto, flags=re.IGNORECASE)
    texto = re.sub(r'p\W*m', 'pm', texto, flags=re.IGNORECASE)

    return texto

def normaliza_ampm(ampm: str) -> str:
    ampm = ampm.lower()
    ampm = re.sub(r'[^ap]', '', ampm)  # deja solo 'a' o 'p'
    if 'p' in ampm:
        return 'pm'
    if 'a' in ampm:
        return 'am'
    return ''

def _normaliza_hora(hora: str) -> str:
    """Devuelve HH:MM en 12 h (todav√≠a sin aplicar AM/PM)."""
    hora = hora.replace('.', ':').replace(',', ':').replace('-', ':')
    # 3 o 4 d√≠gitos pegados -> H:MM / HH:MM
    if re.fullmatch(r'\d{3,4}', hora):
        if len(hora) == 3:   # ej. 945 -> 9:45
            hora = f"{hora[0]}:{hora[1:]}"
        else:                # ej. 1231 -> 12:31
            hora = f"{hora[:2]}:{hora[2:]}"
    # Minuto de 1 d√≠gito -> pad
    if re.fullmatch(r'\d{1,2}:\d{1}', hora):
        h, m = hora.split(':')
        hora = f"{h}:{m.zfill(2)}"
    return hora

def _a_24h(hora_12: str, ampm: str) -> str:
    """Convierte 'H:MM' con am/pm a 'HH:MM' 24 h."""
    h, m = hora_12.split(':')
    h = int(h)
    ampm = normaliza_ampm(ampm)
    if ampm == 'am':
        h = 0 if h == 12 else h
    elif ampm == 'pm':
        h = 12 if h == 12 else h + 12
    return f"{h:02d}:{int(m):02d}"

# --- Formateadores ---
def _formatea_fecha(match) -> str:
    """Caso con mes presente: dd MES yyyy ... -> YYYY-MM-DD HH:MM (24 h)."""
    dia, mes_txt, anio, hora, ampm = match.groups()
    mes_txt = mes_txt.strip('.').lower()
    mes = MESES_MAP.get(mes_txt)
    if not mes:
        return "no fecha"
    hora = _normaliza_hora(hora)
    hora24 = _a_24h(hora, ampm)
    # Usamos datetime para validar (ya que hay mes)
    try:
        dt = datetime.strptime(f"{dia.zfill(2)}/{mes}/{anio} {hora24}", "%d/%m/%Y %H:%M")
        return dt.strftime("%Y-%m-%d %H:%M")
    except Exception:
        # Si por alguna raz√≥n falla, igualmente devolvemos normalizado
        return f"{anio}-{mes}-{dia.zfill(2)} {hora24}"

# --- Parser principal ---

def parse_fecha(original_text: str) -> str:
    texto = preprocesa_fecha(original_text)

    # 1) Caso normal con mes y AM/PM
    match = re.search(
        r'(\d{1,2})[,\s]+([a-z√±]+)\s+(\d{4}).*?(\d{1,2}:\d{1,2}|\d{3,4})\s*([ap][^,:\s]*)',
        texto,
        re.IGNORECASE
    )

    if match:
        return _formatea_fecha(match)

    # 2) Caso sin mes expl√≠cito: "dd,yyyy ... hh:mm/am/pm"
    match2 = re.search(
        r'(\d{1,2})\s*[,]\s*(\d{4})\s*[-.,]?\s*(\d{1,2}[:.]\d{1,2}|\d{3,4})\s*([ap][^,:\s]*)',
        original_text,
        re.IGNORECASE
    )

    if match2:
        dia, anio, hora, ampm = match2.groups()
        hora = _normaliza_hora(hora)
        hora24 = _a_24h(hora, ampm)
        return f"{anio}-**-{str(dia).zfill(2)} {hora24}"

    # 3) Caso con mes pero sin AM/PM ‚Üí hora en crudo
    match3 = re.search(
        r'(\d{1,2})[,\s]+([a-z√±]+)\s+(\d{4}).*?(\d{1,2}[:]\d{1,2})',
        texto,
        re.IGNORECASE
    )

    if match3:
        dia, mes_txt, anio, hora = match3.groups()
        mes_txt = mes_txt.strip('.').lower()
        mes = MESES_MAP.get(mes_txt)
        if not mes:
            return "no fecha"
        hora = _normaliza_hora(hora)
        return f"{anio}-{mes}-{str(dia).zfill(2)} {hora}"

    return "no fecha"

# texto = "bancolombia,itransferencia exitosa ,comprobante no. 0000071600,30,2023 - 03.45 p.m.,producto,cuenta,ahorros,*9790,producto destino,s y g performance sas,ahorros,bancolombia a la mano,377-000223-32,valor enviado, 1.500.000,00,may,origen"

# print(parse_fecha(texto))

"""## funcion para calcular el valor"""


def parse_valor(texto: str) -> int:
    """
    Extrae el valor monetario de un texto OCR de comprobante Bancolombia.
    Retorna un entero o -1 si no se encuentra.
    """
    pattern_valor = re.compile(
        r'(?:'
        r'valor\s*(?:de\s*la\s*)?(?:trans\w{5,12}|tans\w{5,12})'   # transferencia / tansferencia / tansferencla...
        r'|valor\s*enviado'                                        # valor enviado
        r'|valor\s*pagado'                                         # valor pagado
        r'|pagado'                                                 # pagado
        r')'
        r'\D*?\$?\s*([0-9][0-9\.\,]*)',                            # n√∫mero tipo 1.433.000,00
        flags=re.IGNORECASE
    )

    m_valor = pattern_valor.search(texto)
    if m_valor:
        return _parse_currency_to_int(m_valor.group(1))
    return -1


# Ejemplo de uso dentro de tu parser:
# data["valor"] = parse_valor(texto)

"""## funcion principal"""

def parse_transferencia(texto: str):
    data = {}

    # primero que todo, normalizo el texto

    # Comprobante (acepta num√©rico o alfanum√©rico de pagos)
    comp = re.search(r'Comprobante\s*No[:.\s]*([A-Za-z0-9]+)', texto, re.IGNORECASE)
    if comp:
        data["comprobante"] = comp.group(1)

    # Fecha/hora (opcional; puedes ampliar con meses en ES si lo necesitas)
    fecha = parse_fecha(texto)
    if fecha:
      data["fecha"] = fecha
    else:
      data["fecha"] = 'no fecha'

    # Valor (enviado / de la transferencia / pagado)
    m_valor = parse_valor(texto)
    data["valor"] = m_valor

    # Producto origen
    origen = parse_producto_origen(texto)
    if origen:
        data["producto_origen"] = origen

    # Producto destino
    destino = parse_producto_destino(texto)
    if destino:
        data["producto_destino"] = destino

    return data

"""## generamos csv con los resultados"""


def generate_csv_file_results(resultados):
    filas = []

    for filename, texto in resultados.items():
        texto = limpiar_texto(texto)
        data = parse_transferencia(texto)  # tu funci√≥n


        fila = {
            "archivo": filename,
            "comprobante": data.get("comprobante"),
            "fecha": data.get("fecha"),
            "valor": data.get("valor"),
            #"origen_tipo": data.get("producto_origen", {}).get("tipo"),
            #"origen_cuenta": data.get("producto_origen", {}).get("cuenta"),
            "destino_nombre": data.get("producto_destino", {}).get("nombre"),
            "destino_tipo": data.get("producto_destino", {}).get("tipo"),
            "destino_cuenta": data.get("producto_destino", {}).get("cuenta"),
        }
        filas.append(fila)

    df = pd.DataFrame(filas)
    df.to_csv("resultados.csv", index=False)



"""## Proceso cada imagen para obtener json"""
def procesar_resultados(resultados):
    datos = []
    count = 0
    
    for k, v in resultados.items():
        v = limpiar_texto(v)
        _data_parsed = parse_transferencia(v)

        # Agregar el campo "image" y combinar con lo que devuelva _data_parsed
        datos.append({
            "image": k,
            **_data_parsed
        })

        count += 1
    
    return datos

# def procesar_resultados(resultados):
#     datos = []
#     count = 0
    
#     for k, v in resultados.items():
#         v = limpiar_texto(v)
#         _data_parsed = parse_transferencia(v)

#         # opcional: si quieres guardar tambi√©n la clave k y el texto limpio
#         # datos.append({
#         #     "key": k,
#         #     "texto": v,
#         #     "parsed": _data_parsed
#         # })
#         datos.append(_data_parsed)

#         count += 1

#     return datos



def process_data_complete(folder_path):
    resultados = read_and_parse_images(folder_path)
    generate_csv_file_results(resultados)
    return procesar_resultados(resultados)

print('OCR Ready')
# folder_path = "./images/test/"
# print(process_data_complete(folder_path))

# count = 0
# for k, v in resultados.items():

#     v = limpiar_texto(v)

#     _data_parsed = parse_transferencia(v)

#     print(k)
#     print(v)
#     print(_data_parsed)
#     print("--" * 80)

# def parse_transferencia(texto):
#     data = {}

#     # Comprobante
#     comp = re.search(r'Comprobante\s*No[:.\s]*([A-Za-z0-9]+)', texto, re.IGNORECASE)
#     if comp:
#         data["comprobante"] = comp.group(1)

#     # Fecha y hora
#     fecha = re.search(r'(\d{1,2}\s+\w+\s+\d{4}).*?(\d{1,2}[:.]\d{2}\s*(?:a\.m\.|p\.m\.))', texto, re.IGNORECASE)
#     if fecha:
#         fecha_str = fecha.group(1) + " " + fecha.group(2)
#         try:
#             data["fecha"] = datetime.strptime(fecha_str, "%d %b %Y %I.%M %p").strftime("%Y-%m-%d %H:%M")
#         except:
#             data["fecha"] = fecha_str

#     # Valor
#     valor = re.search(r'(?:Valor enviado|Valor de la transferencia|Valor pagado)[^\d]+([\d\.,]+)', texto, re.IGNORECASE)
#     if valor:
#         try:
#             data["valor"] = int(valor.group(1).replace(".", "").replace(",", ""))
#         except:
#             data["valor"] = valor.group(1)

#     # Producto origen
#     origen = re.search(r'Producto origen.*?(Ahorros|Corriente).*?([*\d\- ]+)', texto, re.IGNORECASE)
#     if origen:
#         data["producto_origen"] = {"tipo": origen.group(1), "cuenta": origen.group(2).strip()}

#     # Producto destino (nueva l√≥gica)
#     destino = parse_producto_destino(texto)
#     if destino:
#         data["producto_destino"] = destino

#     return data